name: Test Phoenix Container

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

jobs:
  test-basic:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v5
      
    - name: Set up Python
      uses: actions/setup-python@v6
      with:
        python-version: '3.13'
        
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3
        
    - name: Build Phoenix container
      run: |
        docker compose build
        
    - name: Start Phoenix container
      run: |
        docker compose up -d
        
    - name: Wait for Phoenix to be ready
      run: |
        echo "Waiting for Phoenix to start..."
        for i in {1..30}; do
          if curl -s -f http://localhost:6006 > /dev/null; then
            echo "Phoenix is ready!"
            break
          fi
          echo "Waiting... ($i/30)"
          sleep 5
        done
        
    - name: Verify container is Amazon Linux 2023
      run: |
        os_info=$(docker exec phoenix-al2023 cat /etc/os-release | grep "Amazon Linux")
        echo "Container OS: $os_info"
        if [[ "$os_info" == *"Amazon Linux"* ]]; then
          echo "✅ Confirmed Amazon Linux base image"
        else
          echo "❌ Expected Amazon Linux, got: $os_info"
          exit 1
        fi
        
    - name: Verify Python 3.13
      run: |
        python_version=$(docker exec phoenix-al2023 python3 --version)
        echo "Python version: $python_version"
        if [[ "$python_version" == *"Python 3.13"* ]]; then
          echo "✅ Confirmed Python 3.13"
        else
          echo "❌ Expected Python 3.13, got: $python_version"
          exit 1
        fi
        
    - name: Test Phoenix web interface
      run: |
        response=$(curl -s -w "%{http_code}" -o /dev/null http://localhost:6006)
        if [ "$response" = "200" ]; then
          echo "✅ Phoenix web interface is accessible"
        else
          echo "❌ Phoenix web interface returned HTTP $response"
          exit 1
        fi
        
    - name: Install OpenTelemetry dependencies
      run: |
        pip install -r requirements.txt
        
    - name: Send test telemetry
      run: |
        python send_telemetry.py
        
    - name: Verify telemetry processing
      run: |
        sleep 5
        query='{"query":"query { projects { edges { node { name traceCount } } } }"}'
        response=$(curl -s -H "Content-Type: application/json" -d "$query" http://localhost:6006/graphql)
        trace_count=$(echo "$response" | python -c "import sys, json; data = json.load(sys.stdin); print(data['data']['projects']['edges'][0]['node']['traceCount']) if 'data' in data else print(0)")
        
        if [ "$trace_count" -gt 0 ]; then
          echo "✅ Found $trace_count traces in Phoenix"
        else
          echo "❌ No traces found in Phoenix"
          echo "GraphQL response: $response"
          exit 1
        fi
        
    - name: Show container logs on failure
      if: failure()
      run: |
        echo "=== Container Logs ==="
        docker compose logs
        
    - name: Cleanup
      if: always()
      run: |
        docker compose down -v

  test-llm-integration:
    runs-on: ubuntu-latest
    needs: test-basic
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v5
      
    - name: Set up Python
      uses: actions/setup-python@v6
      with:
        python-version: '3.13'
        
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3
        
    - name: Build all LLM services
      run: |
        cd examples/llm-service
        docker compose build
        
    - name: Start all LLM services
      run: |
        cd examples/llm-service
        docker compose up -d
        
    - name: Wait for services to be ready
      run: |
        cd examples/llm-service
        echo "Waiting for all services to start..."
        for i in {1..60}; do
          if curl -s -f http://localhost:6006 > /dev/null && \
             curl -s -f http://localhost:8080/health > /dev/null && \
             curl -s -f http://localhost:8000/health > /dev/null && \
             curl -s -f http://localhost:8001/health > /dev/null; then
            echo "All services are ready!"
            break
          fi
          echo "Waiting for services... ($i/60)"
          sleep 5
        done
        
    - name: Install test dependencies
      run: |
        cd examples/llm-service
        pip install -r requirements.txt
        
    - name: Run API tests
      run: |
        cd examples/llm-service
        python test_api.py
        
    - name: Test Q&A functionality
      run: |
        response=$(curl -s -X POST http://localhost:8080/api/v1/ask \
          -H "Content-Type: application/json" \
          -H "Authorization: Bearer demo-token" \
          -d '{"question": "What is artificial intelligence?", "context_limit": 3}')
        
        echo "API Response: $response"
        
        # Check if response contains expected fields
        if echo "$response" | grep -q '"answer"' && echo "$response" | grep -q '"confidence"'; then
          echo "✅ Q&A functionality working"
        else
          echo "❌ Q&A functionality failed"
          exit 1
        fi
        
    - name: Test vector search
      run: |
        response=$(curl -s -X POST http://localhost:8001/search \
          -H "Content-Type: application/json" \
          -d '{"query": "machine learning", "limit": 3}')
        
        echo "Vector Search Response: $response"
        
        # Check if response is valid JSON array
        if echo "$response" | python -c "import sys, json; json.load(sys.stdin)" 2>/dev/null; then
          echo "✅ Vector search working"
        else
          echo "❌ Vector search failed"
          exit 1
        fi
        
    - name: Verify Phoenix traces
      run: |
        sleep 10
        query='{"query":"query { projects { edges { node { name traceCount } } } }"}'
        response=$(curl -s -H "Content-Type: application/json" -d "$query" http://localhost:6006/graphql)
        echo "Phoenix GraphQL Response: $response"
        
        trace_count=$(echo "$response" | python -c "import sys, json; data = json.load(sys.stdin); print(data['data']['projects']['edges'][0]['node']['traceCount']) if 'data' in data and data['data']['projects']['edges'] else print(0)" 2>/dev/null || echo "0")
        
        if [ "$trace_count" -gt 0 ]; then
          echo "✅ Found $trace_count traces in Phoenix from LLM services"
        else
          echo "❌ No traces found in Phoenix from LLM services"
          echo "GraphQL response: $response"
          exit 1
        fi
        
    - name: Show service logs on failure
      if: failure()
      run: |
        cd examples/llm-service
        echo "=== Service Logs ==="
        docker compose logs
        
    - name: Cleanup LLM services
      if: always()
      run: |
        cd examples/llm-service
        docker compose down -v
